---
title: "Introduction"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
    code_folding: hide
---

# Abstract

Die mathematisch fundierte Analyse von Kompositionsdaten geht zurück auf die Arbeit von J. Aitchison (1982). Seitdem wurden die Grundlagen u.a. durch Pawlowsky und Egozcue (..) 
kontinuierlich weiter entwickelt. Dank der Entdeckung eines metrischen Raumes für Kompositionsdaten, können die Daten mit fortgeschrittenen statistischen Methoden 
analysiert werden. In dieser Arbeit wird neben der grundsätzlichen Einführung in das Feld der Analyse von Kompositionsdaten, die Anwendung eines Monte-Carlo Expectation-Maximization 
Algorithmus (Steyer and Greven, 2023) für Kompositionsdaten umgesetzt. Die Wirksamkeit des Algorithmus wird anhand von Simulationsdaten evaluiert und anhand eines realen Beispiels 
aus dem Bereich der Geowissenschaften angewandt.

# Motivation

Das Feld der Kompositionsdaten erstreckt sich über eine Vielzahl an Fachbereichen. Sie sind überall dort relevant, wo es um die Analyse von relativen Anteilen eines Ganzen geht. Dazu 
gehören unter anderem auch die geowissenschaftliche Analyse von Sedimentdaten. Warum ist es in diesem Fall relevant und notwendig von Kompositionsdaten zu sprechen?
Der Grund hierfür liegt darin, dass die intuitive Anwendung von standardmäßig etablierten Methoden der multivariaten Datenanalyse auf Kompositionsdaten zu Fehlinterpretationen und Paradoxien
führen kann. Dafür sollen zwei kurze Beispiele angeführt werden, um die Problematik praktisch zu verdeutlichen (Vgl. Pawloswki et al., 2015, p. 1ff):

**Example 1: The scale of proportions**

Relative Daten verhalten sich anders als absolute Daten. Dies wird besonders deutlich, wenn prozentuale Veränderungen betrachtet werden. Stellen Sie sich vor Sie untersuchen zwei 
marine Sedimentschichten, um Rückschlüsse auf die Prozesse Staubeintrag und marine Produktivität zu ziehen. Für den Staubeintrag wird **Illit** als Proxy genommen und für die 
Produktivität Mineral **Kalzit**. Aufgrund der natürlichen Beschaffenheit des Sediments hat Illit einen Anteil von 0.1 % am Sediment und Kalzit einen Anteil von 20% in der 
ersten untersuchten Sedimentschicht. Beim Vergleich mit der zweiten Schicht wird festgestellt, dass der Anteil beider Mineralien sich um 0.1% erhöht hat, der Anteil von Illit ist 
0.2% und der von Kalzit ist 20.1%. Der Anstieg der relativen Veränderung ist also für beide Prozesse gleich. Genausogut ließe sich aber auch sagen, dass sich der Prozess des Staubeintrages
um 100% verstärkt hat und der Prozess der marinen Produktivität lediglich um 5%. In diesem Fall erscheint die Veränderung für den Staubeintrag deutlich relevanter zu sein als für die 
marine Produktivität. Beide Aussagen erscheinen zunächst einmal widersprüchlich und verdeutlichen, dass in einer sauberen Analyse die relative Bedeutung von Veränderungen erfasst werden 
muss. 

**Example 2: spurious correlation**

Ähnlich verwirrende Konsequenzen kann das Auftreten von spurious correlation zeigen. Diese wurde bereits von Karl Pearson (1897) beschrieben und ist eine direkte Folge der Definition 
von Kompositionsdaten als Teil eines Ganzen. Wenn zum Beispiel eine Komposition aus drei Anteilen besteht und zwei davon positiv miteinander korrelieren, dann muss die dritte Komponente 
eine negative Korrelation aufweisen, auch wenn sie in Wirklichkeit unabhängig von den beiden anderen ist. Dies lässt sich auch am oben genannten Beispiel des Staubeintrages und der 
marinen Produktivität verdeutlichen. Beide Prozesse sind eindeutig voneinander unabhängig. Staub der von der Sahara ins Meer geweht wird hat eindeutig nichts mit mariner Produktivität zu tun.
Aber da beide Teile eines ganzen sind, kann es zu einem spurious correlation kommen, wenn der Staubeintrag so dominant wird, dass er den Prozess der marinen Produktivität verdrängt. 
In diesem Fall würde man eine nicht vorhandene negative Korrelation zwischen beiden Prozessen messen. 

Die Herausforderung von Kompositionsdaten sind seit über 100 Jahren bekannt. In den 1980er Jahren wurde von Aitchison eine Methodology eingeführt, die in der Lage war die oben 
genannten Probleme, die Folge der Beschränkungen im Stichprobenraum von Kompositionsdaten sind - dem Simplex, zu lösen. Entscheidend war die Einführung von logratios zur Erfassung der relativen Bezüge der Kompositionsanteile untereinander. Tatsächlich ermöglicht die 
Anwendung von logration Transformationen die Benutzung einer unbeschränkten multivariaten Statistik für Kompositionsdaten. Dies ist möglich, da logration Transformationen eine eins-zu-eins 
Beziehung zwischen den ursprünglichen Kompositionsdaten und ihren Logratios implizieren. Als die beiden bedeutsamsten Transformationen stellten sich die additative log ratio Transformation 
und die zentrierte log ratio Transformation heraus. 
Auf der Arbeit von Aitchison aufbauend, entwickelten mehrere Wissenschaftler (Egozcue, Pawloswki, Mateu-Figuras) in den 2000er Jahren eine algebraisch-geometrische Struktur auf 
dem Grundraum von Kompositionsdaten. Mit diesem metrischen Vektorraum ist es möglich komplexere multivariate Methoden umzusetzen. Ein Beispiel dafür ist die Umsetzung von Maximum 
Likelihood Verfahren zur Berechnung von latenten Parametern. Als Anwendungsbeispiel soll in dieser Arbeit die Methode von Steyer und Greven (2023) für die Durchführung einer Principal Component 
Analyse mit Dichten mit Hilfe eines Monte-Carlo Expectation-Maximisation (MCEM) Algorithmus auf den Fall von Zähl Kompositionen angewendet werden.
Dafür ist es zunächst einmal notwendig die Struktur des Grundraumes von Kompositionsdaten zu definieren. Darauf aufbauend wird die Übertragung des MCEM Algorithmus von Steyer und Greven 
als ein Beispiel für die Anwendungsmöglichkeiten komplexer multivariater Methoden umgesetzt. Die Umsetzung wird einmal am Beispiel von simulierten Daten evaluiert und mit Hilfe eines 
realen geowissenschaftlichen Datensatzes angewandt, um die Mächtigkeit des Ansatzes zu demonstrieren.    

# Basic principles of Compositional Data analysis

Dieses Kapitel führt in die auf Aitchison aufbauende Definition von Kompositionsdaten und ihre wichtigsten Merkmale bzw. Grundprinzipien ein. Darauf aufbauend wird der Vektorraum für 
Kompositionsdaten, die sogenannte Aitchison Geometry, und seine Basisoperationen definiert. Um die Grundlage für die multivariate Datenanalyse zu schaffen, werden die beiden grundlegenden 
Transformationsverfahren, die isometrische logratio Transformation und die zentrierte logratio Transformation erläutert und ihr Bezug zueinander herausgearbeitet. Diese Transformationen 
ermöglichen die Analyse in einem reelen Euklidischen Raum, die für die spätere Umsetzung multivariater Methoden notwendig ist. Im Hinblick auf die Arbeit mit dem praktischen geowissenschaftlichen 
Datensatz, werden außerdem die wichtigsten deskriptiven Methoden zur Darstellung von Kompositionsdaten vorgestellt. 

## Introduction

Wie bereits erwähnt definieren sich Kompositionsdaten dadurch, dass sie sich aus Teilen eines Ganzen zusammensetzen. Daraus folgt ihre Beschreibung als multivariater Datensatz mit 
dessen Anteile relative anstatt absoluter Informationen enthalten, dessen Teile strikt positive sind und die sich zu einer Konstanten aufsummieren. In der Praxis trifft dies auf eine 
Viezahl an Datensätzen zu, z.B. die Stimmenanteile von Parteien bei Wahlen, Anteile von bestimmten Beschäftigungsverhältnissen auf dem Arbeitsmarkt, Organismen in einem Ökosystem oder 
die Anteile chemischer Mineralien in Sedimenten. 
Die grundlegende Charakteristik von Kompositionsdaten als Zusammensetzung von relativen Anteilen eines Ganzen lässt sich wie folgt definieren (Pawloswky-Glahn et al. 2015, p. 8)

**Definition 1: D-part composition**
A (row) vector $\boldsymbol{x} = (x_1, x_2, ..., x_D)$ is a D-part composition when all its compositional parts are strictly positive and carry only relative information.

Der beobachtete Vektor $\boldsymbol{x}$ enthält in der Regel die beobachteten Werte für die $D$ Komponenten, die im Kontext dieser Arbeit Kompositionsteile genannt werden. Die Summe der 
beobachteten Werte wird als Ganzes oder Total bezeichnet. Dabei ist die Größe des Ganzen für die Definition als Kompositionsdaten nicht relevant und es ist auch nicht notwendig, dass diese 
über mehrere Beobachtungen aus einer Grundgesamtheit konstant ist, wie dies bei einigen älteren und exklusiveren Definitionen der Fall ist. Dies kann dadurch verdeutlicht werden, dass die 
Multiplikation des eingeführten Vektors $\boldsymbol{x}$ mit einem positiven Skalar $c > 0$ keine Auswirkungen auf die relativen Anteile der Komponenten hat. Aufgrund dieser Übereinstimmung 
der relativen Informationen, können die in Definition 1 definierten Vektoren als Teil einer Equivalenzklasse von Kompositionsvektoren beschrieben werden, deren Ganzes voneinader abweicht, 
aber deren relative Information identisch ist (Vgl. Pawlowsky-Glahn et al 2015,p.9).  

Hinter den beobachteten Werten steht eine latente Komposition $\boldsymbol{\pi} = (\pi_1, \pi_2, ..., \pi_D)$, welche die zugrunde liegenden Anteile der Komposition enthält. Beobachtete 
Kompositionsdaten sind Representationen einer Komposition, dass heißt einer Equivalenzklasse. 
In diesem Sinne sind die beobachten Häufigkeiten der einzelnen Kompositionsteile Ziehungen aus der zugrunde liegenden Komposition $\boldsymbol{\pi}$. Die zugrunde liegende Komposition entspricht der Dichte einer 
diskreten Verteilung mit $D$ Ausprägungen, es gilt also $\sum_{i=1}^D \pi_i = 1$.

Neben den bereits erwähnten Besonderheiten oder Paradoxien bei der Arbeit mit Kompositionsdaten, gibt es auch eine Reihe von handfesten Problemen bei der Anwendung von multivariaten 
Methooden (Boogart et al. 2013, p. 2):
- Indepentent compositional parts can show spurious correlation
- The covariance of two compositional parts depends on the other compositional parts included in the analysis
- Variance matrixes of compositional data are singular
- The values of compositional data can not follow a normal distribution due to its bounded range.




## Principles of CoDa

## Orthonormal coordinates 

## Descriptive statistics 

## Multivariate techniques 


## Sonstiges

Interpretation des Konvergenzkriteriums: eps = 0.01 bedeutet, dass es pro Komponente im Durchschnitt nur noch eine Abweichung von 1% gibt. 
Bei der Kovarianmatrix beträgt die durchschnittliche Abweichung epsilon/d. D.h. bei kleineren Dimensionalitäten sollte epsilon kleiner 
gewählt werden. 


