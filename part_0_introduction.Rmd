---
title: "Introduction"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
    code_folding: hide
---

# Abstract

Die mathematisch fundierte Analyse von Kompositionsdaten geht zurück auf die Arbeit von J. Aitchison (1982). Seitdem wurden die Grundlagen u.a. durch Pawlowsky und Egozcue (..) 
kontinuierlich weiter entwickelt. Dank der Entdeckung eines metrischen Raumes für Kompositionsdaten, können die Daten mit fortgeschrittenen statistischen Methoden 
analysiert werden. In dieser Arbeit wird neben der grundsätzlichen Einführung in das Feld der Analyse von Kompositionsdaten, die Anwendung eines Monte-Carlo Expectation-Maximization 
Algorithmus (Steyer and Greven, 2023) für Kompositionsdaten umgesetzt. Die Wirksamkeit des Algorithmus wird anhand von Simulationsdaten evaluiert und anhand eines realen Beispiels 
aus dem Bereich der Geowissenschaften angewandt.

# Motivation

Das Feld der Kompositionsdaten erstreckt sich über eine Vielzahl an Fachbereichen. Sie sind überall dort relevant, wo es um die Analyse von relativen Anteilen eines Ganzen geht. Dazu 
gehören unter anderem auch die geowissenschaftliche Analyse von Sedimentdaten. Warum ist es in diesem Fall relevant und notwendig von Kompositionsdaten zu sprechen?
Der Grund hierfür liegt darin, dass die intuitive Anwendung von standardmäßig etablierten Methoden der multivariaten Datenanalyse auf Kompositionsdaten zu Fehlinterpretationen und Paradoxien
führen kann. Dafür sollen zwei kurze Beispiele angeführt werden, um die Problematik praktisch zu verdeutlichen (Vgl. Pawloswki et al., 2015, p. 1ff):

**Example 1: The scale of proportions**

Relative Daten verhalten sich anders als absolute Daten. Dies wird besonders deutlich, wenn prozentuale Veränderungen betrachtet werden. Stellen Sie sich vor Sie untersuchen zwei 
marine Sedimentschichten, um Rückschlüsse auf die Prozesse Staubeintrag und marine Produktivität zu ziehen. Für den Staubeintrag wird **Illit** als Proxy genommen und für die 
Produktivität Mineral **Kalzit**. Aufgrund der natürlichen Beschaffenheit des Sediments hat Illit einen Anteil von 0.1 % am Sediment und Kalzit einen Anteil von 20% in der 
ersten untersuchten Sedimentschicht. Beim Vergleich mit der zweiten Schicht wird festgestellt, dass der Anteil beider Mineralien sich um 0.1% erhöht hat, der Anteil von Illit ist 
0.2% und der von Kalzit ist 20.1%. Der Anstieg der relativen Veränderung ist also für beide Prozesse gleich. Genausogut ließe sich aber auch sagen, dass sich der Prozess des Staubeintrages
um 100% verstärkt hat und der Prozess der marinen Produktivität lediglich um 5%. In diesem Fall erscheint die Veränderung für den Staubeintrag deutlich relevanter zu sein als für die 
marine Produktivität. Beide Aussagen erscheinen zunächst einmal widersprüchlich und verdeutlichen, dass in einer sauberen Analyse die relative Bedeutung von Veränderungen erfasst werden 
muss. 

**Example 2: spurious correlation**

Ähnlich verwirrende Konsequenzen kann das Auftreten von spurious correlation zeigen. Diese wurde bereits von Karl Pearson (1897) beschrieben und ist eine direkte Folge der Definition 
von Kompositionsdaten als Teil eines Ganzen. Wenn zum Beispiel eine Komposition aus drei Anteilen besteht und zwei davon positiv miteinander korrelieren, dann muss die dritte Komponente 
eine negative Korrelation aufweisen, auch wenn sie in Wirklichkeit unabhängig von den beiden anderen ist. Dies lässt sich auch am oben genannten Beispiel des Staubeintrages und der 
marinen Produktivität verdeutlichen. Beide Prozesse sind eindeutig voneinander unabhängig. Staub der von der Sahara ins Meer geweht wird hat eindeutig nichts mit mariner Produktivität zu tun.
Aber da beide Teile eines ganzen sind, kann es zu einem spurious correlation kommen, wenn der Staubeintrag so dominant wird, dass er den Prozess der marinen Produktivität verdrängt. 
In diesem Fall würde man eine nicht vorhandene negative Korrelation zwischen beiden Prozessen messen. 

Die Herausforderung von Kompositionsdaten sind seit über 100 Jahren bekannt. In den 1980er Jahren wurde von Aitchison eine Methodology eingeführt, die in der Lage war die oben 
genannten Probleme, die Folge der Beschränkungen im Stichprobenraum von Kompositionsdaten sind - dem Simplex, zu lösen. Entscheidend war die Einführung von logratios zur Erfassung der relativen Bezüge der Kompositionsanteile untereinander. Tatsächlich ermöglicht die 
Anwendung von logration Transformationen die Benutzung einer unbeschränkten multivariaten Statistik für Kompositionsdaten. Dies ist möglich, da logration Transformationen eine eins-zu-eins 
Beziehung zwischen den ursprünglichen Kompositionsdaten und ihren Logratios implizieren. Als die beiden bedeutsamsten Transformationen stellten sich die additative log ratio Transformation 
und die zentrierte log ratio Transformation heraus. 
Auf der Arbeit von Aitchison aufbauend, entwickelten mehrere Wissenschaftler (Egozcue, Pawloswki, Mateu-Figuras) in den 2000er Jahren eine algebraisch-geometrische Struktur auf 
dem Grundraum von Kompositionsdaten. Mit diesem metrischen Vektorraum ist es möglich komplexere multivariate Methoden umzusetzen. Ein Beispiel dafür ist die Umsetzung von Maximum 
Likelihood Verfahren zur Berechnung von latenten Parametern. Als Anwendungsbeispiel soll in dieser Arbeit die Methode von Steyer und Greven (2023) für die Durchführung einer Principal Component 
Analyse mit Dichten mit Hilfe eines Monte-Carlo Expectation-Maximisation (MCEM) Algorithmus auf den Fall von Zähl Kompositionen angewendet werden.
Dafür ist es zunächst einmal notwendig die Struktur des Grundraumes von Kompositionsdaten zu definieren. Darauf aufbauend wird die Übertragung des MCEM Algorithmus von Steyer und Greven 
als ein Beispiel für die Anwendungsmöglichkeiten komplexer multivariater Methoden umgesetzt. Die Umsetzung wird einmal am Beispiel von simulierten Daten evaluiert und mit Hilfe eines 
realen geowissenschaftlichen Datensatzes angewandt, um die Mächtigkeit des Ansatzes zu demonstrieren.    

# Basic principles of Compositional Data analysis

Dieses Kapitel führt in die auf Aitchison aufbauende Definition von Kompositionsdaten und ihre wichtigsten Merkmale bzw. Grundprinzipien ein. Darauf aufbauend wird der Vektorraum für 
Kompositionsdaten, die sogenannte Aitchison Geometry, und seine Basisoperationen definiert. Um die Grundlage für die multivariate Datenanalyse zu schaffen, werden die beiden grundlegenden 
Transformationsverfahren, die isometrische logratio Transformation und die zentrierte logratio Transformation erläutert und ihr Bezug zueinander herausgearbeitet. Diese Transformationen 
ermöglichen die Analyse in einem reelen Euklidischen Raum, die für die spätere Umsetzung multivariater Methoden notwendig ist. Im Hinblick auf die Arbeit mit dem praktischen geowissenschaftlichen 
Datensatz, werden außerdem die wichtigsten deskriptiven Methoden zur Darstellung von Kompositionsdaten vorgestellt. 

## Introduction

Wie bereits erwähnt definieren sich Kompositionsdaten dadurch, dass sie sich aus Teilen eines Ganzen zusammensetzen. Daraus folgt ihre Beschreibung als multivariater Datensatz mit 
dessen Anteile relative anstatt absoluter Informationen enthalten, dessen Teile strikt positive sind und die sich zu einer Konstanten aufsummieren. In der Praxis trifft dies auf eine 
Viezahl an Datensätzen zu, z.B. die Stimmenanteile von Parteien bei Wahlen, Anteile von bestimmten Beschäftigungsverhältnissen auf dem Arbeitsmarkt, Organismen in einem Ökosystem oder 
die Anteile chemischer Mineralien in Sedimenten. 
Die grundlegende Charakteristik von Kompositionsdaten als Zusammensetzung von relativen Anteilen eines Ganzen lässt sich wie folgt definieren (Pawloswky-Glahn et al. 2015, p. 8)

**Definition 1: D-part composition**
A (row) vector $\boldsymbol{x} = (x_1, x_2, ..., x_D)$ is a D-part composition when all its compositional parts are strictly positive and carry only relative information.

Der beobachtete Vektor $\boldsymbol{x}$ enthält in der Regel die beobachteten Werte für die $D$ Komponenten, die im Kontext dieser Arbeit Kompositionsteile genannt werden. Die Summe der 
beobachteten Werte wird als Ganzes oder Total bezeichnet. Dabei ist die Größe des Ganzen für die Definition als Kompositionsdaten nicht relevant und es ist auch nicht notwendig, dass diese 
über mehrere Beobachtungen aus einer Grundgesamtheit konstant ist, wie dies bei einigen älteren und exklusiveren Definitionen der Fall ist. Dies kann dadurch verdeutlicht werden, dass die 
Multiplikation des eingeführten Vektors $\boldsymbol{x}$ mit einem positiven Skalar $c > 0$ keine Auswirkungen auf die relativen Anteile der Komponenten hat. Aufgrund dieser Übereinstimmung 
der relativen Informationen, können die in Definition 1 definierten Vektoren als Teil einer Equivalenzklasse von Kompositionsvektoren beschrieben werden, deren Ganzes voneinader abweicht, 
aber deren relative Information identisch ist (Vgl. Pawlowsky-Glahn et al 2015,p.9).  

In der Praxis ist es üblich beobachteten Kompositionen eine konstante Summe zuzuordnen, um sie als Teil eines festen Ganzen zu betrachten, z.B. als prozentuale Anteile mit einer konstanten Summe 
von eins oder als ppm (parts per Million). Derartige Vektoren werden in der Literatur auch als *closed data* bezeichnet und die Operation einer Komposition eine konstante Summe zuzuordnen 
als *closure*: 
**Definition 2: closure**
For any compositional vector $\boldsymbol{x} = (x_1, x_2, ..., x_D)$ with positive components, the closure of $\boldsymbol{x}$ to a constant is defined as
$$
\mathcal{C}(\mathbf{x})=\left[\frac{\kappa \cdot x_{1}}{\sum_{i=1}^{D} x_{i}}, \frac{\kappa \cdot x_{2}}{\sum_{i=1}^{D} x_{i}}, \ldots, \frac{\kappa \cdot x_{D}}{\sum_{i=1}^{D} x_{i}}\right]
$$

[TODO: is change between x and pi necessary?]

In der Regel können beobachtete Kompositionen als zufällige Ziehungen aus einer latenten Komposition $\boldsymbol{\pi} = (\pi_1, \pi_2, ..., \pi_D)$ modelliert werden, welche die zugrunde 
liegenden Anteile der Komposition enthält.  
In diesem Sinne sind die beobachten Häufigkeiten der einzelnen Kompositionsteile Ziehungen aus der zugrunde liegenden Komposition $\boldsymbol{\pi}$. Im Kapitel [...] werden wir die beobachteten 
Kompositionsdaten als als count composititions definieren, die einer multinomalialen Zufallsverteilung folgen. Zur Einführung von Kompositionsdaten im Allgemeinen ist es jedoch lediglich 
notwendig darauf zu verweisen, dass im Folgenden für beobachtete Kompositionen eine Notation mit fettgedruckten, kleingeschriebenen Buchstaben (z.B. $\boldsymbol{x}) und für latente Kompositionen 
$\boldsymbol{\pi}$ verwendet wird.
Die zugrunde liegende latente Komposition kann auch als Dichte einer diskreten Verteilung mit $D$ Ausprägungen angesehen werden, es gilt also $\sum_{i=1}^D \pi_i = 1$. An dieser Stelle 
ist es offensichtlich, dass latente Kompositionen ein Beispiel für Kompositionsdaten mit einer konstanten Summe von eins sind.

Anhand dieses Beispiels aus dem Feld der Zufallsvariablen wird deutlich, dass beobachtete Kompositionen sich zwar auf den ersten Blick stark unterscheiden können, z.B. weil sie in unterschiedlichen 
Häufigkeiten oder Einheiten gemessen wurden. Trotzdem können sie dieselben relativen Informationen enthalten.In diesem Sinne sind beobachtete Kompositionsdaten Representationen einer Komposition, 
dass heißt einer Equivalenzklasse. [TODO: Definition einfügen?]

Auf dieser Argumentation aufbauend, kann der Grundraum für Kompositionsdaten definiert werden:

**Definition 3: sample space**
The sample space of compositional data is the simplex,
$\mathcal{S}^{D}=\left\{\boldsymbol{\pi} \in \mathbb{R}^{D} \mid \sum_{j=1}^{D} \pi_{j}=1, \pi_{j} \geq 0 \forall j=1, \ldots, D\right\}$.

Neben den bereits erwähnten Besonderheiten oder Paradoxien bei der Arbeit mit Kompositionsdaten, gibt es auch eine Reihe von handfesten Problemen bei der Anwendung von multivariaten 
Methooden (Boogart et al. 2013, p. 2):
- Indepentent compositional parts can show spurious correlation
- The covariance of two compositional parts depends on the other compositional parts included in the analysis
- Variance matrixes of compositional data are singular
- The values of compositional data can not follow a normal distribution due to its bounded range.

Um diese Probleme zu vermeiden, wurden von WissenschaftlerInnen wie Aitchison (1982) und Pawlowsky-Glahn (2015) Grundsätze entwickelt, die eine mathematisch fundierte Arbeit mit relativen 
Daten ermöglichen. Diese Grundsätze und die von Aitchison entwickelten Operationen eines Euklidischen Vektorraumes auf dem Simplex werden im Folgenden vorgestellt.


## Principles of CoDa

Die Daten auf dem Simplex müssen folgenden drei Prinzipien gerecht werden, um eine robuste und widerspruchsfreie statistische Analyse zu ermöglichen (Aitchison ??, Pawlowsky-Glahn et al. 2015, p. 12):

1. Scale invariance:
Das Prinzip der Scale invariance folgt aus der Definition der Equivalenzklasse von Kompositionen. Es bedeutet, dass die relavtiven Informationen in den Kompositionsteilen unabhängig von 
der Einheit sind, in der diese erfasst werden, solange alle in derselben Einheit gemessen werden. In diesem Sinne muss jede Komposition invariant gegenüber jeder Veränderung der Skalierung 
sein. Mathematisch kann dies für eine beliebige Funktion $f( )$ in $\mathbb{R}^{D}$ wie folgt definiert werden (Pawloswky-Glahn et al. 2015, p.14): The function $f$ is scale invariant if it 
satisfies $f(\lambda \boldsymbol{\pi}) = f(\boldsymbol{\pi})$ for all $\lambda > 0$ and any compistion $\boldsymbol{\pi} \in \mathcal{S}^{D}$.

2. Permutation invariance:
It is required that any change in the order of compositional parts does not influence the analyses, i.e. any function $f$ is permutation invariant if it results in equivalent results when 
the order of the compositional parts is changed.

A typical choice for for $f$ are log ratios for the compositional parts. It is obvious that ratios are scale invariant since $f(\boldsymbol{\pi}) = \pi_1 / \pi_2 = (\lambda * \pi_1) / (\lambda * \pi_2)$.
But ratios depend on the order of the compositional parts. Therefore, the logratio is choosen $f(\boldsymbol{\pi}) = \log(\pi_1 / \pi_2)$. Since $\log(\pi_1 / \pi_2) = - \log(\pi_2 / \pi_1)$ 
it is clear that a change in the order only results in a change of sign and the logratio provides a symmetry with respect to the ordering of parts.

3. Subcompositional coherence:
A subcompisition is a subset of a composition. The last principle of subcompositional coherence states that any the choice a subcomposition does not affect the statistical properties of the 
composition. This principle can be illustrated in two dimensions. The first is that of *subcompositional dominance* and states that the distance between two full compositions must be greater 
or equal to the distance between any two subcomposition. Again, it is useful to mention that the standard Euclidean distance does not fullfill this principle when applied to compositional data.
The second dimension of this principle is that of *ratio preserving*, which means that the choice of a subcomposition does not affect the ratio between the remaining parts.

## Operations of the vector space

Als erstes müssen wir feststellen, dass der im Umgang mit absoluten Werten gewohnte Euklidische Raum als linearer Vektorraum mit seiner metrischen Struktur nicht geeignet ist für Kompositionsdaten. 
Mathematische Operationen auf dem Simplex erscheinen auf den ersten Blick nicht so einfach, wie im gewohnten reelen Raum. Aber auch auf dem Simplex ist es möglich einen Euklidischen Vektorraum 
zu definieren. Dafür benötigen wir zwei Operationen, die Addition und Multiplikation im reelen Raum entsprechen und die angepassten Definitionen vom Skalarprodukt der Norm und der Distanz.

**Definition 4: Perturbation**
For two compositional vectors $\boldsymbol{x}$ and $\boldsymbol{y}$ in \mathcal{S}^{D} their perturbation is defined as:
$$
\mathbf{x} \oplus \mathbf{y}=\mathcal{C}\left[x_{1} y_{1}, x_{2} y_{2}, \ldots, x_{D} y_{D}\right] \in S^{D}
$$

**Definition 5: Powering**
The powering of a compositional vector $\boldsymbol{x}$ in \mathcal{S}^{D} by a constant $a \in \mathbb{R}$ is defined as:
$$
\alpha \odot \mathbf{x}=\mathcal{C}\left[x_{1}^{\alpha}, x_{2}^{\alpha}, \ldots, x_{D}^{\alpha}\right] \in \mathcal{S}^{D}
$$

To complete vector space, the so called the Aitchison geomtry, we need to define a scalar product with its associated norm and distance (Pawloswky-Glahn et al. 2015, p. 26):
**Definition 6: Aitchison inner product**
Inner product of $\mathbf{x}, \mathbf{y} \in S^{D}$,
$$
\langle\mathbf{x}, \mathbf{y}\rangle_{a}=\frac{1}{2 D} \sum_{i=1}^{D} \sum_{j=1}^{D} \ln \frac{x_{i}}{x_{j}} \ln \frac{y_{i}}{y_{j}}
$$
**Definition 7: Aitchison norm**
Norm of $\mathbf{x} \in \mathcal{S}^{D}$,
$$
\|\mathbf{x}\|_{a}=\sqrt{\frac{1}{2 D} \sum_{i=1}^{D} \sum_{j=1}^{D}\left(\ln \frac{x_{i}}{x_{j}}\right)^{2}}
$$
**Definition 8: Aitchison distance**
Distance between $\mathbf{x}$ and $\mathbf{y} \in S^{D}$,
$$
\mathrm{d}_{a}(\mathbf{x}, \mathbf{y})=\|\mathbf{x} \ominus \mathbf{y}\|_{a}=\sqrt{\frac{1}{2 D} \sum_{i=1}^{D} \sum_{j=1}^{D}\left(\ln \frac{x_{i}}{x_{j}}-\ln \frac{y_{i}}{y_{j}}\right)^{2}}
$$

Those operations define a whole vector space on the simplex (TODO: definition of a vector space). For historical reasons it is called the Aitchison geometry. But in mathematical terms it 
is also a real Euclidean space or a finite dimensional real Hilbert space.
This allows now for the use of all statistical methods that are available for the standard Euclidean space. (TODO: umformulieren)

## Orthonormal coordinates 

## Descriptive statistics 

Es wurde bereits herausgearbeitet, dass die üblichen Methoden einer auf absoluten Werten basierenden statistischen Analyse für Kompositionsdaten 
nicht geeignet sind. Stattdessen sollten Methoden verwendet werden, die im Einklang mit der Aitchison Geometry (chapter [...]) stehen. Diese werden 
im Folgenden aufgeführt und im kapitel [...] am praktischen Datensatz umgesetzt. The observed data matrix $\boldsymbol{x_i} = (x_{i 1}, \ldots, x_{i D})$ with $i = 1, \ldots, n$ contains *n* rows of observed 
compositions with *D* columns for the compositional parts. 

Standardmethoden der beschreibenden multivariaten statistischen Analyse beinhalten in der Regel measures of central tendency and dispersion, i.e. the 
arithmetric mean and the variance of the multivariate data (Vgl. Pawlowsky-Glahn et al. 2015, p. 66). Im Kontext der Aitchison Geometry werden diese 
durch *center* (Aitchison, 1997), *variation matrix* and *total variance* (Aitchison, 1986) ersetzt.

**Definition 9: Sample center**
The closed geometric mean is a measure for the central tendancy of a compositional sample. It is called *center*.  For the observed data matrix $\boldsymbol{x}$ 
it is defined as: $\operatorname{cen}(\mathbf{x})=\hat{\mathbf{g}}=\mathcal{C}\left[\hat{g}_{1}, \hat{g}_{2}, \ldots, \hat{g}_{D}\right]$
with $\hat{g}_{j}=\left(\prod_{i=1}^{n} x_{i j}\right)^{1 / n}, j=1,2, \ldots, D$.

This corresponds to: 
$$
\begin{equation*}
\overline{\mathbf{x}}=\frac{1}{N} \odot \bigoplus_{n=1}^{N} \mathbf{x}_{n}=\operatorname{clr}^{-1}\left(\frac{1}{N} \sum_{n=1}^{N} \operatorname{clr}\left(\mathbf{x}_{n}\right)\right)=\mathscr{C}\left[\exp \left(\frac{1}{N} \sum_{n=1}^{N} \ln \left(\mathbf{x}_{n}\right)\right)\right] \tag{4.1}
\end{equation*}
$$
With $\mathscr{C}$ being the closure operation.

TODO: How to compute that

**Definition 10: Variation matrix**
The *variation matrix* is a measure for dispersion in a compositional sample. It is defined as: 
$$
\mathbf{T}=\left(\begin{array}{cccc}
t_{11} & t_{12} & \ldots & t_{1 D} \\
t_{21} & t_{22} & \ldots & t_{2 D} \\
\vdots & \vdots & \ddots & \vdots \\
t_{D 1} & t_{D 2} & \ldots & t_{D D}
\end{array}\right), \quad t_{i j}=\operatorname{var}\left(\ln \frac{x_{i}}{x_{j}}\right)
$$
TODO: add normalized version? -> if so introduce **balances** here as well

**Definition 11: Sample total variance**
The *Sample total variance* is a measure for global dispersion in a compositional sample. It is defined as: 
$$
\operatorname{totvar}[\mathbf{x}]=\frac{1}{2 D} \sum_{i, j=1}^{D} \operatorname{var}\left(\ln \frac{x_{i}}{x_{j}}\right)=\frac{1}{2 D} \sum_{i, j=1}^{D} t_{i j}=\frac{1}{n} \sum_{k=1}^{n} \mathrm{~d}_{a}^{2}\left(\mathbf{x}_{k}, \hat{\mathbf{g}}\right)
$$
TODO: change index i to k or l

Since any constant cancels out when taking ratios the measures of dispersion do not depend on any closure, i.e. the scale of the observerd data.

## Multivariate techniques 


## Sonstiges

Interpretation des Konvergenzkriteriums: eps = 0.01 bedeutet, dass es pro Komponente im Durchschnitt nur noch eine Abweichung von 1% gibt. 
Bei der Kovarianmatrix beträgt die durchschnittliche Abweichung epsilon/d. D.h. bei kleineren Dimensionalitäten sollte epsilon kleiner 
gewählt werden. 


